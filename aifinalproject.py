# -*- coding: utf-8 -*-
"""AiFinalProject.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1O_zJ6mIpA7lr_TZsWx0noJ1U88UcOjT1
"""

#These commands download the pokemon image dataset from Kaggle
#You will need to upload a kaggle.json file to use the Kaggle API
!pip install -q kaggle

! mkdir ~/.kaggle
! cp kaggle.json ~/.kaggle/

! chmod 600 ~/.kaggle/kaggle.json

! kaggle datasets download thedagger/pokemon-generation-one

!unzip /content/pokemon-generation-one.zip

#Importing important packages
import cv2
import numpy as np
import pathlib
import tensorflow as tf
import time
from IPython.display import Image
from matplotlib import pyplot as plt
data_dir = "/content/dataset"
data_dir = pathlib.Path(data_dir)

#OLD CODE, NOW USE tf.keras.preprocessing.image.ImageDataGenerator TO GENERATE TRAINING DATA
#Start setting up the data to a usable format
data_dir = "/content/dataset"
data_dir = pathlib.Path(data_dir)

labels = list(data_dir.glob('*/'))

thing = []
for i in range(len(labels)):
  thing.append(str(labels[i]))
thing2 = [w[17:] for w in thing]
#print(len(labels))
pkmn = list(data_dir.glob('Abra/*.jpg'))

#Counts pics of abra
image_count = len(list(data_dir.glob('Abra/*.jpg')))
#print(image_count)

#Displays pics of abra
img = cv2.imread(str(pkmn[40]))
img_cvt=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
#plt.imshow(img_cvt)

Image(str(pkmn[40]))

trainx = []
trainy = []

for label in thing2:
  images = list(data_dir.glob(label + '/*.jpg'))
  for newimg in images:
    print(label)
    im = cv2.imread(str(newimg))
    trainx.append(im)
    trainy.append(label)
len(trainy)
len(trainx)

display(trainx[600])
print(trainy[600])

#OLD MODEL, VERY POOR RESULTS
#.028 MAX ACCURACY

model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(224, 224, 3)),
  tf.keras.layers.Dense(512, activation='relu'),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Dense(149, activation='softmax')
])

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

#model.summary()

#CURRENT MODEL, DECENT RESULTS
input_shape=(224, 224, 3)
model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(8, kernel_size=(3, 3), activation='relu',padding='same',input_shape=input_shape),
    tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides=2),
    tf.keras.layers.Conv2D(16, kernel_size=(5, 5), activation='relu'),
    tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides=2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(120, activation='relu'),
    tf.keras.layers.Dense(84, activation='relu'),
    tf.keras.layers.Dense(149, activation='softmax')
])
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
#model.summary()

CLASS_NAMES = np.array([item.name for item in data_dir.glob('*') if item.name != "dataset"])
CLASS_NAMES

#Get the data ready to feed into neural network
data_dir = "/content/dataset/"
data_dir = pathlib.Path(data_dir)
image_count = len(list(data_dir.glob('*/*.jpg')))

image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)
BATCH_SIZE = 32
IMG_HEIGHT = 224
IMG_WIDTH = 224
STEPS_PER_EPOCH = np.ceil(image_count/BATCH_SIZE)
train_data_gen = image_generator.flow_from_directory(directory=str(data_dir),
                                                     batch_size=BATCH_SIZE,
                                                     shuffle=True,
                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),
                                                     classes = list(CLASS_NAMES),
                                                     class_mode="sparse")

#This was used to peek at the batches to make sure labels and pictures lined up
#However, it stopped working when chaging class_mode to "sparse" in the above code cell. Unsure as to why.
def show_batch(image_batch, label_batch):
  plt.figure(figsize=(10,10))
  for n in range(25):
      ax = plt.subplot(5,5,n+1)
      plt.imshow(image_batch[n])
      plt.title(CLASS_NAMES[label_batch[n]==1][0].title())
      plt.axis('off')
image_batch, label_batch = next(train_data_gen)
show_batch(image_batch, label_batch)

#Train the model
model.fit(train_data_gen, epochs = 6)

#Takes a file path and a label
def recognize(path, true_label):
  new_img = cv2.imread(path)
  img_cvt=cv2.cvtColor(new_img, cv2.COLOR_BGR2RGB)
  res = cv2.resize(img_cvt, dsize=(224, 224), interpolation=cv2.INTER_CUBIC)
  plt.imshow(res)

  print("Actual Label: " + true_label)
  predicted = model.predict(res[None, :, :])[0]
  print("Neural network recognizes this image as: ", CLASS_NAMES[np.argmax(predicted)])


recognize("/content/dataset/Butterfree/811d90692780433eba8a88e6f7fe68bc.jpg","Butterfree")